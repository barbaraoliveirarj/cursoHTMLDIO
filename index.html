<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>O que é Inteligência Artificial?</title>
</head>
<body>
    <h1 id="topo">O que é Inteligência Artificial?</h1>

    <ul>
        <li><a href="#tipos">Tipos de inteligência artificial – IA fraca vs. IA forte</a></li>
        <li><a href="#deep">Deep learning vs. Aprendizado de máquina</a></li>
        <li><a href="#modelos">A ascensão dos modelos generativos</a></li>
        <li><a href="#aplicacoes">Aplicações da inteligência artificial</a></li>
        <li><a href="#historia">História de inteligência artificial: datas e nomes importantes</a></li>
    </ul>

    <p>Enquanto várias definições de inteligência artificial (IA) surgiram ao longo das últimas décadas, John McCarthy oferece a 
        seguinte definição em um artigo de 2004<sup><a href="#referencias" target="_blank">[1]</a></sup>:</p>
        <blockquote>"É a ciência e engenharia da criação de máquinas inteligentes, especialmente programas de computação inteligentes. 
        Está relacionado à tarefa semelhante de usar computadores para entender a inteligência humana, mas a IA não precisa se limitar 
        a métodos de observação biológica"</blockquote>
    <p>No entanto, décadas antes dessa definição, o nascimento da discussão sobre inteligência artificial foi denotado pelo trabalho 
        seminal de Alan Turing, <strong>Computing Machinery and Intelligence</strong><sup><a href="#referencias" target="_blank">[2]</a>
        </sup>, publicado em 1950. Nesse artigo, Turing, muitas vezes chamado de <mark>"pai da ciência da computação"</mark>, faz a 
        seguinte pergunta: "As máquinas pensam?" Partindo desse ponto, ele oferece um teste, hoje conhecido como "Turing Test", em que 
        um interrogador humano tentaria distinguir entre uma resposta de texto de um computador e de um ser humano. Embora esse teste 
        tenha sido submetido a muito escrutínio desde sua publicação, permanece como uma parte importante da história da IA, bem como 
        um conceito contínuo dentro da filosofia, pois utiliza ideias em torno da linguística.</p>
    <p>Stuart Russell e Peter Norvig, em seguida, publicaram, <strong>Inteligência Artificial: Uma Abordagem Moderna</strong>
        <sup><a href="#referencias" target="_blank">[3]</a></sup>, tornando-se um dos principais livros didáticos no estudo da IA. 
        Na obra, aprofundam-se em quatro objetivos potenciais ou definições de IA, que distingue sistemas computacionais com base na 
        racionalidade e pensamento vs. ação:</p>
    <ol>
        <li>Abordagem humana:
            <ul>
                <li>Sistemas que pensam como humanos</li>
                <li>Sistemas que agem como humanos</li>
            </ul>
        </li>
        <br>
        <li>Abordagem ideal:
            <ul>
                <li>Sistemas com pensamento racional</li>
                <li>Sistemas com atos racionais</li>
            </ul>
        </li>
    </ol>
    <blockquote>A definição de Alan Turing teria se enquadrado na categoria de <mark>"sistemas que agem como humanos"</mark>.</blockquote>
    <p>Em sua forma mais simples, a inteligência artificial é um campo que combina ciência da computação e conjuntos de dados 
        robustos para possibilitar a solução de problemas. Engloba também subcampos de aprendizado de máquina e deep learning, 
        frequentemente mencionados com a inteligência artificial. Essas disciplinas são compostas por algoritmos de IA que 
        procuram criar sistemas especializados para fazer previsões ou classificações com base em dados de entrada.</p>
    <p>Ao longo dos anos, a inteligência artificial passou por muitos ciclos de entusiasmo, mas até mesmo para os céticos, 
        o lançamento do ChatGPT da OpenAI parece marcar um ponto de mudança de direção. Na última vez em que a IA generativa 
        apareceu com essa dimensão, os avanços se deram na visão computacional, mas agora o salto ocorre no processamento de 
        linguagem natural. E não somente linguagem: os modelos generativos também podem aprender a gramática de código de software, 
        moléculas, imagens naturais e uma variedade de outros tipos de dados.</p> 
    <p>As aplicações para essa tecnologia estão crescendo a cada dia e estamos apenas começando a explorar as possibilidades. Mas à 
        medida que o entusiasmo em torno do uso de IA nos negócios decola,as conversas relativas à ética
        <sup><a href="#referencias" target="_blank">[4]</a></sup> tornam-se extremamente importantes.</p>

    <hr>

    <h2 id="tipos">Tipos de inteligência artificial – IA fraca vs. IA forte</h2>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <p>A IA fraca, também chamada de Narrow AI ou Artificial Narrow Intelligence (ANI), é treinada e concentrada na IA para a execução 
        de tarefas específicas. A IA fraca impulsiona a maior parte da IA que nos cerca hoje. 'Narrow' (estreito) pode ser uma descrição 
        mais precisa para esse tipo de IA, pois é tudo menos fraco; ela permite a criação de alguns aplicativos muito robustos, como o Siri 
        da Apple, o Alexa da Amazon, o IBM Watson e veículos autônomos.</p>
    <p>A IA forte é composta por Inteligência Artificial Geral (AGI) e Superinteligência Artificial (ASI). Inteligência geral artificial 
        (AGI), ou IA geral, é uma forma teórica de IA onde uma máquina teria uma inteligência igual à dos humanos; ela teria uma consciência 
        de autoconhecimento capaz de resolver problemas, aprender e planejar para o futuro. A Superinteligência artificial (ASI), também 
        conhecida como superinteligência, superaria a inteligência e a capacidade do cérebro humano. Embora a IA forte ainda seja inteiramente 
        teórica, sem exemplos práticos em uso atualmente, isso não significa que os pesquisadores de IA também não estejam explorando seu 
        desenvolvimento. Enquanto isso, os melhores exemplos de ASI podem vir da ficção científica, como HAL, o assistente de computador 
        super-humano e rebelado de 2001: Uma Odisseia no Espaço.</p>

    <hr>

    <h2 id="deep">Deep learning vs. Aprendizado de máquina</h2>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <p>Como o deep learning e o aprendizado de máquina tendem a ser usados de forma intercambiável, vale a pena observar as nuances entre 
        os dois. Conforme mencionado acima, tanto o deep learning quanto o aprendizado de máquina são subcampos da inteligência artificial, 
        e o deep learning é, na verdade, um subcampo do aprendizado de máquina.</p>
    <p>O deep learning é, na verdade, composto por redes neurais. O "Deep" (profundo) do deep learning refere-se a uma rede neural composta 
        por mais de três camadas, que conteria as entradas e a saída, que pode ser considerada um algoritmo de deep learning. Isso geralmente 
        é representado pelo diagrama abaixo.</p>
    <p>A forma como o deep learning e o aprendizado de máquina diferem está na maneira como cada algoritmo aprende. O deep learning 
        automatiza grande parte da parte de extração de recursos do processo, eliminando parte da intervenção humana manual necessária e 
        permitindo o uso de conjuntos de dados maiores. Você pode pensar no deep learning como "aprendizado de máquina escalável" como 
        observou Lex Fridman na mesma palestra do MIT acima. O aprendizado de máquina clássico, ou “não profundo”, depende mais da intervenção 
        humana para aprender. Especialistas humanos determinam a hierarquia dos recursos para entender as diferenças entre as entradas de 
        dados, geralmente exigindo dados mais estruturados para aprender.</p>
    <p>O aprendizado de máquina "profundo" pode aproveitar conjuntos de dados rotulados, também conhecidos como aprendizado supervisionado, 
        para informar seu algoritmo, mas não exige necessariamente um conjunto de dados rotulado. É capaz de ingerir dados não estruturados 
        em sua forma bruta (como texto e imagens) e pode determinar automaticamente a hierarquia dos recursos que distinguem diferentes 
        categorias de dados umas das outras. Diferentemente do aprendizado de máquina, não exige intervenção humana para processar dados, 
        o que nos permite dimensionar o aprendizado de máquina de maneiras mais interessantes.</p>
    <img src="./imgs/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork.png" alt="Diagrama ilustrando uma rede neural composta de 5 camadas (uma 
    camada de entrada, três camadas ocultas e uma camada de saída), ou seja um 'Deep Learning'.">
    
    <hr>

    <h2 id="modelos">A ascensão dos modelos generativos</h2>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <p>IA generativa refere-se a modelos de deep learning capazes de obter dados brutos, digamos, toda a Wikipedia ou as obras coletadas 
        de Rembrandt, e “aprender” a gerar resultados estatisticamente prováveis quando solicitado. Em um nível elevado, os modelos 
        generativos codificam uma representação simplificada dos seus dados de treinamento e os extraem para criar um novo trabalho semelhante,
        mas não idêntico aos dados originais.</p>
    <p>Os modelos generativos têm sido utilizados há anos em estatísticas para analisar dados numéricos. O surgimento do deep learning, 
        no entanto, tornou possível estendê-los a imagens, voz e outros tipos de dados complexos. Entre os modelos da primeira classe a 
        alcançar esse feito cruzado estavam os autoencoders variacionais, ou <abbr title="Variational AutoEncoder">VAEs</abbr>, introduzidos 
        em 2013. Os VAEs foram os primeiros modelos de deep learning a serem amplamente usados para gerar imagens e voz realistas.</p>
    <p>Os VAEs abriram as comportas da represa da modelagem generativa profunda, facilitando o uso de modelos em escala", afirma Akash 
        Srivastava<sup><a href="#referencias" target="_blank">[5]</a></sup>, especialista em IA generativa do Laboratório de IA MIT-IBM Watson. 
        <mark>”Grande parte do que consideramos como IA generativa hoje começou aqui”</mark>.</p>
    <p>Exemplos iniciais de modelos, como <abbr title="Generative Pre-Training Transformer 3">GPT-3</abbr>, 
        <abbr title="Bidirectional Encoder Representations for Transformers">BERT</abbr> ou 
        <abbr title="Junção dos nomes do artista Salvador Dalí e do personagem da Pixar WALL-E">DALL-E 2</abbr>, 
        mostraram as possibilidades. O futuro são modelos treinados em um amplo conjunto de dados não rotulados que podem ser 
        usados em diversas tarefas, com ajuste fino mínimo. Sistemas que executam tarefas específicas em um único domínio estão dando lugar a 
        uma ampla IA que aprende de forma mais geral e funciona em todos os domínios e problemas. Modelos básicos, treinados em grandes conjuntos 
        de dados não identificados e ajustados para uma variedade de aplicações, estão impulsionando essa mudança.</p>
    <p>Quando se trata de IA generativa, prevê-se que os modelos de base vão acelerar drasticamente a adoção da IA nas empresas. 
        A redução dos requisitos de rotulagem tornará muito mais fácil para as empresas mergulharem de cabeça e a automação altamente 
        precisa e eficiente orientada por IA que possibilitam significará que muito mais empresas poderão implantar IA em uma variedade 
        maior de situações de missão crítica. Para a IBM, a esperança é que o poder dos modelos básicos possa acabar sendo levado a todas 
        as empresas em um ambiente de nuvem híbrida sem atrito.</p>

    <hr>

    <h2 id="aplicacoes">Aplicações da inteligência artificial</h2>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <p>Atualmente, há inúmeras aplicações reais de sistemas de IA. Abaixo estão alguns dos casos de uso mais comuns:</p>
    <ol>
        <li><strong>Reconhecimento de voz</strong>: também conhecido como reconhecimento automático de voz (ASR), reconhecimento de voz por computador, 
            ou voz-para-texto, é um recurso que usa processamento de linguagem natural (PNL) para processar a voz humana no formato 
            escrito. Muitos dispositivos móveis incorporam reconhecimento de voz em seus sistemas para realizar pesquisas por voz, como 
            o Siri, ou oferecem mais acessibilidade no envio mensagens de texto. </li>
        <li><strong>Atendimento ao cliente</strong>:  Os agentes virtuais on-line estão substituindo os agentes humanos na jornada do cliente. Respondem 
            a perguntas frequentes (FAQs) sobre assuntos como envio, ou fornecem orientação personalizada, fazem vendas cruzadas de 
            produtos ou oferecem sugestões de tamanhos para os usuários, mudando nossa forma de encarar o envolvimento do cliente em 
            sites e plataformas de redes sociais. Alguns exemplos são bots de mensagens em sites de comércio eletrônico com agentes 
            virtuais, aplicativos de mensagens, como o Slack e o Facebook Messenger e tarefas normalmente realizadas por assistentes 
            virtuais e assistentes de voz.</li>
        <li><strong>Computer Vision</strong>: essa tecnologia de IA permite que computadores e sistemas colham informações significativas de imagens 
            digitais, vídeos e outras entradas visuais e, com base nessas entradas, podem agir. Essa capacidade de apresentar 
            recomendações a distingue das tarefas de reconhecimento de imagem. Alimentada por redes neurais convolucionais, a Computer 
            Vision tem aplicações em aplicação de etiquetas em fotos em redes sociais, imagens de radiologia na área da saúde e 
            carros autônomos na indústria automotiva.  </li>
        <li><strong>Mecanismos de recomendação</strong>: utilizando dados de comportamento de consumo passados, os algoritmos de IA podem ajudar a 
            descobrir tendências de dados que podem ser usadas para desenvolver estratégias de venda cruzada mais eficazes. É 
            utilizado para fazer recomendações complementares relevantes aos clientes durante o processo de checkout para varejistas 
            on-line.</li>
        <li><strong>Negociação automatizada de ações</strong>: projetada para otimizar carteiras de ações, as plataformas de negociação de alta 
            frequência orientadas por IA realizam milhares ou até milhões de negociações por dia sem intervenção humana.</li>
    </ol>

    <hr>

    <h2 id="historia">História de inteligência artificial: datas e nomes importantes</h2>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <p>A ideia da "máquina que pensa" remonta à Grécia antiga. Mas desde o advento da computação eletrônica (e em relação a alguns 
        dos tópicos discutidos neste artigo) eventos e marcos importantes na evolução da inteligência artificial incluem o seguinte:</p>
    <ul>
        <li>1950: Alan Turing publica Computing Machinery and Intelligence. No artigo, Turing, famoso por quebrar o código ENIGMA 
            dos nazistas durante a Segunda Guerra Mundial, propõe responder à pergunta "as máquinas pensam?" e apresenta o Teste 
            de Turing para determinar se um computador pode demonstrar a mesma inteligência (ou os resultados da mesma inteligência) 
            que um ser humano. O valor do teste de Turing tem sido debatido desde então.</li>
        <li>1956: John McCarthy cunhou o termo "inteligência artificial" na primeira conferência de IA no Dartmouth College. 
            (McCarthy inventaria a língua Lisp.) Mais tarde naquele ano, Allen Newell, J.C. Shaw e Herbert Simon criaram o Logic 
            Theorist, o primeiro programa de software de IA em execução.</li>
        <li>1967: Frank Rosenblatt constrói o Mark 1 Perceptron, o primeiro computador baseado em uma rede neural que “aprendeu” 
            por tentativa e erro. Apenas um ano depois, Marvin Minsky e Seymour Papert publicam um livro intitulado Perceptrons, 
            que se torna um trabalho marcante sobre redes neurais e, pelo menos por um tempo, um argumento contra futuros projetos 
            de pesquisa de redes neurais.</li>
        <li>Década de 1980: redes neurais que usam um algoritmo de propagação retroativa para treinar a si mesmo tornam-se 
            amplamente utilizadas em aplicações de IA.</li>
        <li>1997: Deep Blue da IBM vence o então campeão mundial de xadrez Garry Kasparov, em uma partida de xadrez (e revanche).</li>
        <li>2011: o IBM Watson derrota os campeões Ken Jennings e Brad Rutter no Jeopardy!</li>
        <li>2015: O supercomputador Minwa da Baidu utiliza um tipo especial de rede neural profunda chamada rede neural convolucional 
            para identificar e categorizar imagens com uma taxa de precisão maior do que a de um ser humano comum.</li>
        <li>2016: O programa AlphaGo da DeepMind, alimentado por uma rede neural profunda, vence Lee Sodol, o campeão mundial de 
            Go, em uma partida de cinco jogos. A vitória é significativa dado o grande número de movimentos possíveis no jogo 
            (mais de 14,5 trilhões após apenas quatro movimentos!). Mais tarde, o Google comprou a DeepMind por US$ 400 milhões.</li>
        <li>2023: o aumento de grandes modelos de linguagem, ou LLMs, como o ChatGPT, criará uma enorme mudança no desempenho 
            da IA e seu potencial para gerar valor empresarial. Com essas novas práticas de IA generativa, os modelos de deep 
            learning podem ser treinados previamente em grandes quantidades de dados brutos e não rotulados.</li>
    </ul>

    <hr>

    <h3 id="referencias">Referências:</h3>
    <small><a href="#topo">^ Voltar ao topo</a></small>
    <ol>
    <li>MCCARTHY, J. <a href="https://www-formal.stanford.edu/jmc/whatisai.pdf" target="_blank">What is Artificial Intelligence?</a><sub>[pdf]</sub></li>
    <li>TURING, A. M. <a href="https://redirect.cs.umbc.edu/courses/471/papers/turing.pdf" target="_blank">Computing Machinery and Intelligence</a><sub>[pdf]</sub></li>
    <li>RUSSELL S., NORVIG P.<a href="https://aima.cs.berkeley.edu/" target="_blank">Artificial Intelligence: A Modern Approach</a><sub>[link externo]</sub></li>
    <li>IBM. <a href="https://www.ibm.com/br-pt/topics/ai-ethics" target="_blank">O que é a ética na IA?</a><sub>[link externo]</sub></li>
    <li>IBM. <a href="https://research.ibm.com/blog/what-is-generative-AI" target="_blank">What is generative AI?</a><sub>[link externo]</sub></li>
    </ol>
    <small>Artigo retirado do website da <a href="https://www.ibm.com/br-pt" target="_blank">IBM</a>, em  26 de dezembro de 2023. Página elaborada exclusivamente para fins didáticos.</small>
    
    <hr>
    
</body>
<footer>
    <p><small>Revisando HTML - Babi Oliveira - 2023</small></p>
</footer>
</html>